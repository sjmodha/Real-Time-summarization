{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path1='F:/trec-RTS/25617/bm25_list'\n",
    "#path1='F:/TREC-RTS/25617/0.1JM_Rank'\n",
    "\n",
    "#path1='F:/TREC-RTS/25617/1000Dirichlet'\n",
    "\n",
    "\n",
    "path='C:/Users/lenovo/Google Drive/PHD share folder/paper/trec experiment/analysis'\n",
    "os.chdir(path)\n",
    "ip1=['MB226','MB229','MB230','MB239','MB254','MB256','MB258','MB265','MB267','MB276','MB286','MB319','MB320','MB332','MB351']\n",
    "ip2=['MB358','MB361','MB362','MB363','MB365','MB371','MB377','MB381','MB382','MB391','MB392','MB409','MB410','MB414','MB419']  \n",
    "ip3=['MB420','MB425','MB431','MB436','MB438','MB440','RTS1','RTS10','RTS13','RTS14','RTS19','RTS2','RTS21','RTS24','RTS25']\n",
    "ip4=['RTS27','RTS28','RTS31','RTS32','RTS35','RTS36','RTS37','RTS4','RTS43','RTS5','RTS6']\n",
    "ip=['MB226','MB229','MB230','MB239','MB254','MB256','MB258','MB265','MB267','MB276','MB286','MB319','MB320','MB332','MB351','MB358','MB361','MB362','MB363','MB365','MB371','MB377','MB381','MB382','MB391','MB392','MB409','MB410','MB414','MB419','MB420','MB425','MB431','MB436','MB438','MB440','RTS1','RTS10','RTS13','RTS14','RTS19','RTS2','RTS21','RTS24','RTS25','RTS27','RTS28','RTS31','RTS32','RTS35','RTS36','RTS37','RTS4','RTS43','RTS5','RTS6']\n",
    "#ip=['MB229']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "qrels = pd.read_csv('qrels.txt', sep=' ')\n",
    "#runfile = pd.read_csv('merge_B_Jelinek0.2_0.6_normal_0.4_21_15_final_luchen.txt', sep=' ')\n",
    "epoch = pd.read_csv('rts2016-batch-tweets2dayepoch.txt', sep=' ')\n",
    "cluster = pd.read_csv('clusters.txt', sep='\\t')\n",
    "\n",
    "#print qrels.head() #print runfile.head() print cluster.head() print epoch.head()\n",
    "cluster.drop(cluster[[3]],axis=1,inplace=True)\n",
    "cluster.drop(cluster[[3]],axis=1,inplace=True)\n",
    "cluster.drop(cluster[[3]],axis=1,inplace=True)\n",
    "#cluster.info() epoch.info()\n",
    "#print \"number of unique:\",epoch['tweet_id'].nunique()\n",
    "#print \"number of unique:\",epoch['tweet_id','date'].nunique()\n",
    "#print \"number of duplicated:\",epoch[epoch.duplicated(['tweet_id','date'])].count()\n",
    "epoch=epoch.drop_duplicates(subset=['tweet_id','date'])\n",
    "fqrels = pd.read_csv('Qrel_formated.txt', sep=' ',header=None)\n",
    "fqrels.columns=['tweet_id','profile','text']\n",
    "fqrels=fqrels.drop_duplicates(subset=['tweet_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3339 entries, 0 to 67507\n",
      "Data columns (total 4 columns):\n",
      "profile      3339 non-null object\n",
      "q0           3339 non-null object\n",
      "tweet_id     3339 non-null int64\n",
      "relevance    3339 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 130.4+ KB\n"
     ]
    }
   ],
   "source": [
    "qn=qrels[(qrels['relevance'] > 0)]\n",
    "qn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path1)\n",
    "\n",
    "for i,p in enumerate(ip):\n",
    "    qn=qrels[(qrels['relevance'] > 0) & (qrels['profile'] == p)]\n",
    "    #qn.count()\n",
    "\n",
    "\n",
    "    ij=qn.merge(epoch,how='inner',on=['tweet_id'])\n",
    "    #ij.count()\n",
    "    #ij.head()\n",
    "#ijc=ij.merge(cluster,how='inner',on=['tweet_id','profile'])\n",
    "    ijc= pd.merge(ij,cluster,how='inner',on=['tweet_id','profile'])\n",
    "    #ijc.count()\n",
    "    ijc=ijc.drop(ijc[[5]],axis=1)\n",
    "    ijc=ijc.drop(ijc[[1]],axis=1)\n",
    "    #ijc.info()\n",
    "    tqrel = ijc.merge(fqrels,how='inner',on=['tweet_id'])\n",
    "    tqrel=tqrel.sort_values(by=['date'],ascending=[True])\n",
    "    \n",
    "    os.chdir(path1)\n",
    "#os.mkdir(p)\n",
    "    path2=path1 +\"/\" + p\n",
    "    os.chdir(path2)\n",
    "\n",
    "    fn = p + '_qrel.txt'\n",
    "    ijc=ijc.sort_values(ijc.columns[3],ascending=[True])\n",
    "    ijc.to_csv(fn,index=False,sep=' ')\n",
    "    textstring=  p +'text.txt'\n",
    "    tqrel.to_csv(textstring,index=False,sep= ' ')\n",
    "    \n",
    "    fnstr= p + '_qrel.txt'\n",
    "    fnstr1 = p + '.txt'\n",
    "    gq = pd.read_csv(fnstr, sep=' ')\n",
    "#gq.info()\n",
    "    pt=pd.read_csv(fnstr1,sep=',',header=None)\n",
    "    pt.columns=['date','profile','qo','tweet_id','rank','score','text']\n",
    "#pt.info()\n",
    "#pt[pt.duplicated(['tweet_id'])]\n",
    "#gq.drop(gq[[0]],axis=1,inplace=True)\n",
    "   # pt.drop(pt[[6]],axis=1,inplace=True)\n",
    "    pt.drop(pt[[2]],axis=1,inplace=True)\n",
    "    pt1=pt.drop_duplicates(subset='tweet_id')\n",
    "    pt1.reset_index(drop=True)\n",
    "    mt=gq.merge(pt1,how='inner',on=['tweet_id','profile','date'])\n",
    "#mt.info()\n",
    "#mt.head()\n",
    "#mt=mt.sort_values(mt.columns[3],mt.columns[5],ascending=[True,True])\n",
    "    mt=mt.sort_values(by=['date','rank'],ascending=True)\n",
    "    mt.to_csv(p +'_qrelinrank.txt',index=False,sep=' ')\n",
    "    pt11=pt1['tweet_id'].tolist()\n",
    "    gq1=gq['tweet_id'].tolist()\n",
    "\n",
    "    ngq=list(set(gq1)-set(pt11))\n",
    "    if len(ngq) > 0 :\n",
    "        ngq_df = pd.DataFrame(ngq)\n",
    "        ngq_df.columns=['tweet_id']\n",
    "        qrelmissRank_df= pd.merge(ngq_df,tqrel,how='inner',on=['tweet_id'])\n",
    "#qrelmissRank_df= pd.merge(qrelmissRank_df,epoch,how='inner',on=['tweet_id'])\n",
    "        #nqrelmissRank_df= pd.merge(ngq_df,ijc,how='inner',on=['tweet_id'])\n",
    "        qrelmissRank_df.to_csv(p + '_qrelmissrank.txt',index=False,sep= ' ')\n",
    "    #path_rn='C:/Users/lenovo/Google Drive/PHD share folder/paper/trec experiment/rishabh/11417'\n",
    "\n",
    "    #os.chdir(path_rn)\n",
    "    os.chdir(path1)\n",
    "    #run_df=pd.read_csv(\"merge_B_Dirichlet_0.6_normal_NER_0.4_1000.0 6.0_3.0_+4+3final_doc_l_grid_ndcg1.txt\",sep=' ',header=None)\n",
    "\n",
    "    #run_df=pd.read_csv(\"merge_B_Jelinek_0.6_normal_NER_0.4_0.1 6.0_3.0_+4+3final_doc_l_grid_ndcg1_again.txt\",sep=' ',header=None)\n",
    "    run_df=pd.read_csv(\"merge_B_BM25_0.6_normal_NER_0.4_0.1 12_10_+4+3final_doc_l_grid_ndcg1.txt\",sep=' ',header=None)\n",
    "#run_df.drop(run_df[[7]],axis=1,inplace=True)\n",
    "    run_df.drop(run_df[[6]],axis=1,inplace=True)\n",
    "\n",
    "    run_df.columns=['date','profile','q0','tweet_id','rank','score']\n",
    "    run_df.drop(run_df[[2]],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    run_df=run_df[(run_df['profile'] == p)]\n",
    "#run_df.info()\n",
    "    run_merge_df =pd.merge(mt,run_df,how='inner',on=['tweet_id','profile','date'])\n",
    "\n",
    "#run_merge_df.head()\n",
    "\n",
    "\n",
    "    os.chdir(path1)\n",
    "    os.chdir(p)\n",
    "    run_merge_df=run_merge_df.sort_values(by=['date','rank_y'],ascending=[True,True])\n",
    "    run_merge_df.to_csv(p+\"_System_summary.txt\",index=False,sep=' ')\n",
    "\n",
    "#run_df.to_csv(p+\"_System_summary.csv\",index=False)\n",
    "#Qrel_insumm_df =  pd.DataFrame(list(set(mt['tweet_id'].tolist()) & set(run_df['tweet_id'].tolist())))\n",
    "#Qrel_insumm_df.head()\n",
    "    Qrel_notinsumm_df =  pd.DataFrame(list(set(mt['tweet_id'].tolist()) - set(run_df['tweet_id'].tolist())))\n",
    "    if(Qrel_notinsumm_df.empty==False):\n",
    "        Qrel_notinsumm_df.columns=[\"tweet_id\"]\n",
    "        Qrel_notinsumm_df = pd.merge(Qrel_notinsumm_df,mt,how='inner',on=['tweet_id'])\n",
    "        Qrel_notinsumm_df.info()\n",
    "#run_merge_df.info()\n",
    "        Qrel_notinsumm_df=Qrel_notinsumm_df.sort_values(by=['date','rank'],ascending=[True,True])\n",
    "        Qrel_notinsumm_df.to_csv(p +'System_notincluded.txt',index=False,sep=' ')\n",
    "    \n",
    "    #if not (wt_summ_df.empty):\n",
    "    wt_summ_df =  pd.DataFrame(list(set(run_df['tweet_id'].tolist()) - set(mt['tweet_id'].tolist())))\n",
    "    #wt_summ_df.info()\n",
    "    if(wt_summ_df.empty==False):\n",
    "        wt_summ_df.columns=[\"tweet_id\"]\n",
    "        wt_summ_df = pd.merge(wt_summ_df,pt1,how='inner',on='tweet_id')\n",
    "    #wt_summ_df.head()\n",
    "#wt_summ_df.info()\n",
    "        wt_summ_df=wt_summ_df.sort_values(by=['date','rank'],ascending=[True,True])\n",
    "        wt_summ_df.to_csv(p + \"NonRelevantTweetinsummary.txt\",index=False,sep= ' ')\n",
    "        \n",
    "    os.chdir(path1)\n",
    "    if(run_merge_df.empty==False):\n",
    "        a=run_merge_df['cluster'].nunique()\n",
    "    else:\n",
    "        a=0\n",
    "    b=len(run_merge_df)\n",
    "    \n",
    "    cls = cluster[(cluster['profile'] == p)]\n",
    "    if(cls.empty==False):\n",
    "        c= cls['cluster'].nunique()\n",
    "    else:\n",
    "        c=0\n",
    "    if(wt_summ_df.empty==False):\n",
    "        nrt = len(wt_summ_df)\n",
    "    else:\n",
    "        nrt=0\n",
    "    #qn=qrels[(qrels['relevance'] > 0)\n",
    "    #print a, b, c\n",
    "    rt = b-a\n",
    "    statstr = p + \" \" + str(c) + \" \" + str(a) + \" \" + str (rt) + \" \" + str(nrt)+\"\\n\"\n",
    "    #os.chdir(os.pardir)\n",
    "    fstat = open('stats.txt',\"a+\")\n",
    "    fstat.write(statstr)\n",
    "    fstat.close()\n",
    "    \n",
    "    daydf=ijc\n",
    "    daydf=daydf.drop_duplicates(subset=['date'])\n",
    "    #daydf=daydf.drop_duplicates(subset=['cluster'])\n",
    "\n",
    "    summdf = run_df\n",
    "    summdf=summdf.drop_duplicates(subset=['date'])\n",
    "    sat=(daydf['date']).tolist()\n",
    "    sdt=(summdf['date']).tolist()\n",
    "    gs=[20160802,20160803,20160804,20160805,20160806,20160807,20160808,20160809,20160810,20160811]\n",
    "    sday = list(set(gs) - set(sat))\n",
    "    xr = list(set(gs) - set(sdt))\n",
    "    #x = set(sdt) &  set(sday)\n",
    "    xssd = len(list(set(gs) - set(sdt)))\n",
    "    xgssd = len(list(set(gs) - set(sat)))\n",
    "    wsd = len(list(set(xr)-set(sday)))\n",
    "    fsd = len(list(set(sday)-set(xr)))\n",
    "\n",
    "    sdstr = p + \" \" +str(xgssd) + \" \" + str(xssd) + \" \" +str(wsd) +\" \" + str(fsd)+\"\\n\"\n",
    "    foutsd = open(\"silentday.txt\",'a+')\n",
    "    foutsd.write(sdstr)\n",
    "    foutsd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>profile</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>763705348339314689</td>\n",
       "      <td>MB267</td>\n",
       "      <td>RT is reporting:Ukrainian, president, orders, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>763705444795879424</td>\n",
       "      <td>MB371</td>\n",
       "      <td>Inside the startup that could help GM beat #Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>763707390957121536</td>\n",
       "      <td>RTS37</td>\n",
       "      <td>RT, 0t_p0ppy: This Male beluga was dead at 15 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>763708431165456384</td>\n",
       "      <td>MB267</td>\n",
       "      <td>RT, : BREAKING: Ukrainian president orders for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>763709475530440704</td>\n",
       "      <td>MB267</td>\n",
       "      <td>RT, : 1/5 US government has seen nothing so fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id profile  \\\n",
       "0  763705348339314689   MB267   \n",
       "1  763705444795879424   MB371   \n",
       "2  763707390957121536   RTS37   \n",
       "3  763708431165456384   MB267   \n",
       "4  763709475530440704   MB267   \n",
       "\n",
       "                                                text  \n",
       "0  RT is reporting:Ukrainian, president, orders, ...  \n",
       "1  Inside the startup that could help GM beat #Go...  \n",
       "2  RT, 0t_p0ppy: This Male beluga was dead at 15 ...  \n",
       "3  RT, : BREAKING: Ukrainian president orders for...  \n",
       "4  RT, : 1/5 US government has seen nothing so fa...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fqrels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=[20160802,20160803,20160804,20160805,20160806,20160807,20160808,20160809,20160810,20160811]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path1)\n",
    "daydf=ijc\n",
    "daydf=daydf.drop_duplicates(subset=['date','cluster'])\n",
    "daydf=daydf.drop_duplicates(subset=['cluster'])\n",
    "\n",
    "summdf = run_df\n",
    "summdf=summdf.drop_duplicates(subset=['date'])\n",
    "sat=(daydf['date']).tolist()\n",
    "sdt=(summdf['date']).tolist()\n",
    "gs=[20160802,20160803,20160804,20160805,20160806,20160807,20160808,20160809,20160810,20160811]\n",
    "sday = list(set(gs) - set(sat))\n",
    "xr = list(set(gs) - set(sdt))\n",
    "#x = set(sdt) &  set(sday)\n",
    "xssd = len(list(set(gs) - set(sdt)))\n",
    "xgssd = len(list(set(gs) - set(sat)))\n",
    "wsd = len(list(set(xr)-set(sday)))\n",
    "fsd = len(list(set(sday)-set(xr)))\n",
    "\n",
    "sdstr = p + \" \" +str(xgssd) + \" \" + str(xssd) + \" \" +str(wsd) +\" \" + str(fsd)+\"\\n\"\n",
    "foutsd = open(\"silentday.txt\",'a+')\n",
    "foutsd.write(sdstr)\n",
    "foutsd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>date</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB226</td>\n",
       "      <td>761356311606984705</td>\n",
       "      <td>1</td>\n",
       "      <td>20160805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB226</td>\n",
       "      <td>763555729126993921</td>\n",
       "      <td>1</td>\n",
       "      <td>20160811</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile            tweet_id  relevance      date  cluster\n",
       "0   MB226  761356311606984705          1  20160805        1\n",
       "2   MB226  763555729126993921          1  20160811        2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summdf\n",
    "daydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 22 16\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path1)\n",
    "a=run_merge_df['cluster'].nunique()\n",
    "b=len(run_merge_df)\n",
    "cls = cluster[(cluster['profile'] == p)]\n",
    "\n",
    "c= cls['cluster'].nunique()\n",
    "nrt = len(wt_summ_df)\n",
    "#qn=qrels[(qrels['relevance'] > 0)\n",
    "print a, b, c\n",
    "rt = b-a\n",
    "statstr = p + \" \" + str(c) + \" \" + str(a) + \" \" + str (rt) + \" \" + str(nrt)+\"\\n\"\n",
    "#os.chdir(os.pardir)\n",
    "#fstat = open('stats.txt',\"a+\")\n",
    "#fstat.write(statstr)\n",
    "#fstat.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>date</th>\n",
       "      <th>cluster</th>\n",
       "      <th>rank_x</th>\n",
       "      <th>score_x</th>\n",
       "      <th>text</th>\n",
       "      <th>rank_y</th>\n",
       "      <th>score_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [profile, tweet_id, relevance, date, cluster, rank_x, score_x, text, rank_y, score_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(set(mt['tweet_id'].tolist()) - set(run_df['tweet_id'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\TREC-RTS\\\\25617\\\\0.1JM_Rank'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
