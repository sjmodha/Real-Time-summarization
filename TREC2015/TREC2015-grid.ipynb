{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This file is to take run file (as an input argument) and ground truth non-redundant tweets, judgment pools\n",
    "#to compute ndcg@k score.\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "from sets import Set\n",
    "import argparse\n",
    "path='F:/TREC2015/Analysis'\n",
    "os.chdir(path)\n",
    "file_qrels_path = 'qrels.txt'\n",
    "clusters_path = 'clusters-2015.json'\n",
    "file_tweet2day = 'tweet2dayepoch.txt'\n",
    "run_path='jmsmoothing20_13.txt'\n",
    "\n",
    "K = 10\n",
    "days = []\n",
    "for i in range(20, 30):\n",
    "    days.append(\"201507%s\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take qrels to generate dictionary of {topic number:{tweetid:gain}} \n",
    "#where gain is 0(spam/junk, not interesting), 0.5(somewhat interesting), 1(very interesting)\n",
    "qrels_dt = {}\n",
    "clusters_day_dt = {}\n",
    "file_qrels = open(file_qrels_path, \"r\")\n",
    "lines = file_qrels.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip().split()\n",
    "    topic_ind = line[0]\n",
    "    tweetid = line[2]\n",
    "    score = int(line[3])\n",
    "    if score == -1:\n",
    "        score = 0\n",
    "    else:\n",
    "        if score == 3:\n",
    "            score = 1\n",
    "        else:\n",
    "            if score == 4:\n",
    "                score = 2\n",
    "    if topic_ind not in qrels_dt:\n",
    "        qrels_dt[topic_ind] = {}\n",
    "        clusters_day_dt[topic_ind] = {}\n",
    "        for day in days:\n",
    "            clusters_day_dt[topic_ind][day] = []\n",
    "    qrels_dt[topic_ind][tweetid] = score * 1.0 / 2\n",
    "file_qrels.close()\n",
    "\n",
    "#Take tweet2dayepoch.txt (tweets from judgment pool) and store the mapping data in dictionary of {tweetid:day}\n",
    "tweet2day_dt = {}\n",
    "file_tweet2day = open(\"tweet2dayepoch.txt\", \"r\")\n",
    "lines = file_tweet2day.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip().split()\n",
    "    tweet2day_dt[line[0]] = line[1]\n",
    "file_tweet2day.close()\n",
    "\n",
    "#Take clustering protocol file and generate dictionary of {topic number:{day:[tweets]}} and dictionary of {topic number:{day:{tweet:clusterid}}}\n",
    "clusters_clusterid_dt = {}\n",
    "file_clusters = open(clusters_path, \"r\")\n",
    "data = json.load(file_clusters)\n",
    "topics = data[\"topics\"]\n",
    "clusterid = 1\n",
    "for topic in sorted(topics.keys()):\n",
    "    topic_ind = topic[topic.index(\"MB\") + 2:]\n",
    "    topic_ind = topic_ind.encode(\"utf-8\")\n",
    "    if topic_ind not in clusters_clusterid_dt:\n",
    "        clusters_clusterid_dt[topic_ind] = {}\n",
    "    clusters_json = topics[topic][\"clusters\"]\n",
    "    for i in range(len(clusters_json)):\n",
    "        clusters_json[i] = [s.encode(\"utf-8\") for s in clusters_json[i]]\n",
    "    for cluster in clusters_json:\n",
    "        for tweetid in cluster:\n",
    "            clusters_day_dt[topic_ind][tweet2day_dt[tweetid]].append(tweetid)\n",
    "            clusters_clusterid_dt[topic_ind][tweetid] = clusterid\n",
    "        clusterid = clusterid + 1\n",
    "file_clusters.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2471\n",
      "IR-RIS\t0.2255\n",
      "IR-RIS\t0.2255\n",
      "IR-RIS\t0.2255\n",
      "IR-RIS\t0.2255\n",
      "IR-RIS\t0.2255\n",
      "IR-RIS\t0.2294\n",
      "IR-RIS\t0.2294\n",
      "IR-RIS\t0.2294\n",
      "IR-RIS\t0.2294\n",
      "IR-RIS\t0.2294\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n",
      "IR-RIS\t0.2451\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "#path_rn = 'F:/TREC2015\\Analysis\\Nov-2017-result\\jm result\\jm2015'\n",
    "path_rn = 'F:/TREC2015\\Analysis\\August-2017-result\\diri'\n",
    "#path_rn = 'F:/TREC2015\\Analysis\\August-2017-result\\BM25-result'\n",
    "r='d'\n",
    "os.chdir(path_rn)\n",
    "count =0\n",
    "fout=open(\"g/rdata_new.txt\",\"a+\")\n",
    "\n",
    "fout1=open(\"g/result.txt\",\"a+\")\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    run_path=file\n",
    "    #Take input run and generate dictionary of {topic number:{day:[tweetids]}}\n",
    "    runname = ''\n",
    "    run_dt = {}\n",
    "    file_run = open(run_path, \"r\")\n",
    "    lines = file_run.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip().split()\n",
    "        runname = line[6]\n",
    "        topic_ind = line[1][line[1].index(\"MB\") + 2:]\n",
    "        #Only consider the 51 topics selected by NIST\n",
    "        if topic_ind in qrels_dt:\n",
    "            if topic_ind not in run_dt:\n",
    "                run_dt[topic_ind] = {}\n",
    "            day = line[0]\n",
    "            if day not in run_dt[topic_ind]:\n",
    "                run_dt[topic_ind][day] = []\n",
    "            tweetid = line[3]\n",
    "            run_dt[topic_ind][day].append(tweetid)\n",
    "    file_run.close()\n",
    "\n",
    "    # print \"runtag\".ljust(len(runname)) + \"\\ttopic\\tnDCG\"\n",
    "    #Compute ndcg\n",
    "    total_score = 0.0\n",
    "    for topic_ind in sorted(qrels_dt):\n",
    "        topic_score = 0.0\n",
    "        exist_clusterids = Set()\n",
    "        for day in days:\n",
    "            interesting = False\n",
    "            max_gain_dt = {}\n",
    "            tweets_fromprotocol = clusters_day_dt[topic_ind][day]\n",
    "            for tweetid in tweets_fromprotocol:\n",
    "                clusterid = clusters_clusterid_dt[topic_ind][tweetid]\n",
    "                if clusterid not in exist_clusterids:\n",
    "                    interesting = True\n",
    "                    if clusterid not in max_gain_dt:\n",
    "                        max_gain_dt[clusterid] = qrels_dt[topic_ind][tweetid]\n",
    "                    else:\n",
    "                        max_gain_dt[clusterid] = max(max_gain_dt[clusterid], qrels_dt[topic_ind][tweetid])\n",
    "            if interesting:\n",
    "                if topic_ind in run_dt and day in run_dt[topic_ind]:\n",
    "                    ndcg = 0\n",
    "                    gains = []\n",
    "                    for tweetid in run_dt[topic_ind][day]:\n",
    "                        gain = 0\n",
    "                        if tweetid in clusters_day_dt[topic_ind][day]:\n",
    "                            clusterid = clusters_clusterid_dt[topic_ind][tweetid]\n",
    "                            if clusterid not in exist_clusterids:\n",
    "                                exist_clusterids.add(clusterid)\n",
    "                                gain = qrels_dt[topic_ind][tweetid]\n",
    "                                if clusterid in max_gain_dt:\n",
    "                                    gain = max_gain_dt[clusterid]\n",
    "                        gains.append(gain)\n",
    "                    rank_cut = min(len(gains), K)\n",
    "                    dcg = 0.0\n",
    "                    for i in range(rank_cut):\n",
    "                        gain = gains[i]\n",
    "                        dcg = dcg + (pow(2, gain) - 1) * 1.0 / math.log(i + 2, 2)\n",
    "                    #Compute idcg\n",
    "                    top_gains = max_gain_dt.values()\n",
    "                    top_gains.sort(reverse = True)\n",
    "                    rank_cut = min(len(top_gains), K)\n",
    "                    idcg = 0.0\n",
    "                    top_gains = top_gains[:rank_cut]\n",
    "                    for i in range(rank_cut):\n",
    "                        gain = top_gains[i]\n",
    "                        idcg = idcg + (pow(2, gain) - 1) * 1.0 / math.log(i + 2, 2)\n",
    "                    if idcg != 0:\n",
    "                        ndcg = dcg / idcg\n",
    "                    topic_score = topic_score + ndcg\n",
    "            else:\n",
    "                if topic_ind not in run_dt or day not in run_dt[topic_ind]:\n",
    "                    topic_score = topic_score + 1\n",
    "        topic_score = topic_score / len(days)\n",
    "        \n",
    "        if(r=='b'):\n",
    "            if (len(run_path)== 86) :\n",
    "                #lamda=float(run_path[37]+ run_path[38]+ run_path[39]+run_path[40])\n",
    "                maxth=float(run_path[36]+ run_path[37]+run_path[38])\n",
    "                minth=float(run_path[41]+ run_path[42])\n",
    "            else:\n",
    "                maxth=float(run_path[36]+ run_path[37]+run_path[38])\n",
    "                minth=float(run_path[41]+ run_path[42])\n",
    "        \n",
    "        elif(r=='j'):\n",
    "                maxth=int(run_path[3:5])\n",
    "                minth=int(run_path[8:10])\n",
    "        elif(r=='d'):\n",
    "                if (len(run_path)== 86) :\n",
    "                    maxth=int(run_path[36:38])\n",
    "                    minth=int(run_path[41:42])\n",
    "                else:\n",
    "                    maxth=int(run_path[36:37])\n",
    "                    minth=int(run_path[40:41])\n",
    "        wrstr = topic_ind + \" \"+ str(round(topic_score,4)) + ' ' +  str(minth)+ ' ' +str(maxth)+  '\\n'\n",
    "        fout.write(wrstr)\n",
    "                        \n",
    "        # print \"%s\\tMB%s\\t%.04f\" % (runname, topic_ind, topic_score)\n",
    "        total_score = total_score + topic_score\n",
    "    total_score = total_score / len(qrels_dt)\n",
    "    print \"%s\\t%.04f\" % (runname, total_score)\n",
    "    tempstr = run_path + \" \" + str(round(total_score,4)) +\"\\n\"\n",
    "    fout1.write(tempstr)\n",
    "fout1.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "86\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "#path_rn = 'F:/TREC2015\\Analysis\\Nov-2017-result\\jm result\\jm2015'\n",
    "path_rn = 'F:/TREC2015\\Analysis\\August-2017-result\\diri'\n",
    "#path_rn = 'F:/TREC2015\\Analysis\\August-2017-result\\BM25-result'\n",
    "r='j'\n",
    "os.chdir(path_rn)\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    print len(file)\n",
    "   ## maxt=int(file[3:5])\n",
    "    mint=(file[8:10])\n",
    "   # print maxt,mint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'merge_B_Diri_0.6_normal_NER_0.4_0.1 10.0_3.0_+4+3final_doc_l_grid_ndcg1_again_list.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[36:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[41:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
