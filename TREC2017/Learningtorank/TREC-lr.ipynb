{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nolearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe86cc1dde27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnesterov_momentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlinearities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mnolearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlasagne\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgreedy_order\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nolearn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../lib')  # noqa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pdb\n",
    "from sklearn.metrics import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "import csv\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.nonlinearities import softmax\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from greedy_order import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ipath='F:/TREC-RTS2016/25617/'\n",
    "jpath='F:/TREC-RTS2016/25617/0.1JM_rank/'\n",
    "dpath='F:/TREC-RTS2016/25617/1000Dirichlet/'\n",
    "bpath='F:/TREC-RTS2016/25617/bm25_list/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ip=['MB320','MB256']\n",
    "ip=['MB226','MB229','MB230','MB239','MB254','MB256','MB258','MB265','MB267','MB276','MB286','MB319','MB320','MB332','MB351','MB358','MB361','MB362','MB363','MB365','MB371','MB377','MB381','MB382','MB391','MB392','MB409','MB410','MB414','MB419','MB420','MB425','MB431','MB436','MB438','MB440','RTS1','RTS10','RTS13','RTS14','RTS19','RTS2','RTS21','RTS24','RTS25','RTS27','RTS28','RTS31','RTS32','RTS35','RTS36','RTS37','RTS4','RTS43','RTS5','RTS6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df=pd.DataFrame()\n",
    "#train_df.columns=['tweet_id','JM','Diri','BM25','Class']\n",
    "\n",
    "fout=open('C:/Users/lenovo/AnacondaProjects/learning-to-rank-master/experiments/train_deatil.txt','a+')\n",
    "for i,p in enumerate(ip):\n",
    "    qrels=pd.read_csv('C:/Users/lenovo/Google Drive/PHD share folder/paper/trec experiment/analysis/qrels.txt',sep=' ')\n",
    "    qn=qrels[qrels['profile'] == p]\n",
    "    qn=qn[['profile','tweet_id','relevance']]\n",
    "    os.chdir(ipath)\n",
    "    #print (p)\n",
    "    os.chdir(jpath+p)\n",
    "    jdf=pd.read_csv(p+'.txt',header=None,sep=',',names=['date', 'profile','q0','tweet_id','rank','score','text'])\n",
    "    jdf=jdf.drop_duplicates(subset=['tweet_id','profile'])\n",
    "    jdf=jdf[['profile','tweet_id','score']]\n",
    "    jdf.head()\n",
    "\n",
    "    os.chdir(dpath+p)\n",
    "    ddf=pd.read_csv(p+'.txt',header=None,sep=',',names=['date', 'profile','q0','tweet_id','rank','score','text'])\n",
    "    ddf=ddf.drop_duplicates(subset=['tweet_id','profile'])\n",
    "\n",
    "    ddf=ddf[['profile','tweet_id','score']]\n",
    "    ddf.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "    os.chdir(bpath+p)\n",
    "    bdf=pd.read_csv(p+'.txt',header=None,sep=',',names=['date', 'profile','q0','tweet_id','rank','score','text'])\n",
    "    bdf=bdf.drop_duplicates(subset=['tweet_id','profile'])\n",
    "\n",
    "    bdf=bdf[['profile','tweet_id','score']]\n",
    "        \n",
    "    #n_df =  pd.DataFrame(list(set(ddf['tweet_id'].tolist()) & set(jdf['tweet_id'].tolist())))\n",
    "    \n",
    "    jd_df=pd.merge(jdf,ddf,how='inner',on=['tweet_id','profile'])\n",
    "    bdj_df=pd.merge(jd_df,bdf,how='inner',on=['tweet_id','profile'])\n",
    "    #bdj_df.info()\n",
    "    qbdj_df=pd.merge(bdj_df,qn,how='inner',on=['tweet_id','profile'])\n",
    "    qbdj_df.columns=['profile','tweet_id','JM','Diri','BM25','Class']\n",
    "    qbdj_df['JM']=round(qbdj_df['JM'],2)                \n",
    "    qbdj_df['Diri']=round(qbdj_df['Diri'],2)                \n",
    "    qbdj_df['BM25']=round(qbdj_df['BM25'],2)\n",
    "    \n",
    "    qbdj_df['Class'] = qbdj_df.Class.apply(lambda x: x if not pd.isnull(x) else 0)\n",
    "    qbdj_df['Class']=qbdj_df.Class.astype(int)\n",
    "    qbdj_df.info()\n",
    "    \n",
    "    instr = 'profile'+ \"  \" + str(len(qn['tweet_id']))+\"  \"+str(len(qbdj_df['tweet_id'])) +'\\n'\n",
    "    fout.write(instr)\n",
    "                          \n",
    "    qbdj_df.to_csv('C:/Users\\lenovo\\AnacondaProjects\\learning-to-rank-master\\experiments/sample.txt',encoding='UTF-8',index=False,header=None,mode='a')\n",
    "fout.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ip2017=['RTS101']\n",
    "path2017='F:/TREC2017/Analysis/Ranklist/'\n",
    "jpath2017='F:/TREC2017/Analysis/Ranklist/jm112/'\n",
    "dpath2017='F:/TREC2017/Analysis/Ranklist/diri/'\n",
    "bpath2017='F:/TREC2017/Analysis/Ranklist/bm25/'\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip2017=[]\n",
    "with open('F:/TREC2017/Analysis/tid95-2.txt','r') as fin:\n",
    "    line= fin.readlines()\n",
    "    for l in line:\n",
    "        l=l.strip().split(' ')\n",
    "        #tpn=l[0]\n",
    "        tpid=l[1]\n",
    "        ip2017.append(tpid)      \n",
    "#print len(ip2017)\n",
    "#ip2017.remove('RTS63')\n",
    "#ip2017.remove('RTS164')\n",
    "#\n",
    "#ip2017.remove('RTS182')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ip2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fout=open('C:/Users/lenovo/AnacondaProjects/learning-to-rank-master/experiments/test_deatil.txt','a+')\n",
    "qrels=pd.read_csv('F:/TREC2017\\Analysis\\Qrel/rts2017-batch-qrels.txt',sep=' ',names=['profile','q0','tweet_id','relevance'])\n",
    "\n",
    "for i,p in enumerate(ip2017):\n",
    "    \n",
    "    qn=qrels[qrels['profile'] == p]\n",
    "    qn=qn[['profile','tweet_id','relevance']]\n",
    "    \n",
    "    os.chdir(path2017)\n",
    "    #print (p)\n",
    "    os.chdir(jpath2017+p)\n",
    "    jdf=pd.read_csv(p+'.txt',header=None,sep=',',names=['date', 'profile','q0','tweet_id','rank','score','text'])\n",
    "    jdf=jdf.drop_duplicates(subset=['tweet_id','profile'])\n",
    "    jdf=jdf[['profile','tweet_id','score']]\n",
    "    jdf.head()\n",
    "\n",
    "    os.chdir(dpath2017+p)\n",
    "    ddf=pd.read_csv(p+'.txt',header=None,sep=',',names=['date', 'profile','q0','tweet_id','rank','score','text'])\n",
    "    ddf=ddf.drop_duplicates(subset=['tweet_id','profile'])\n",
    "\n",
    "    ddf=ddf[['profile','tweet_id','score']]\n",
    "    #ddf.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "    os.chdir(bpath2017+p)\n",
    "    bdf=pd.read_csv(p+'.txt',header=None,sep=',',names=['date', 'profile','q0','tweet_id','rank','score','text'])\n",
    "    bdf=bdf.drop_duplicates(subset=['tweet_id','profile'])\n",
    "\n",
    "    bdf=bdf[['profile','tweet_id','score']]\n",
    "        \n",
    "    #n_df =  pd.DataFrame(list(set(ddf['tweet_id'].tolist()) & set(jdf['tweet_id'].tolist())))\n",
    "    \n",
    "    jd_df=pd.merge(jdf,ddf,how='inner',on=['tweet_id','profile'])\n",
    "    bdj_df=pd.merge(jd_df,bdf,how='inner',on=['tweet_id','profile'])\n",
    "    #bdj_df.info()\n",
    "    bdj_df.columns=['profile','tweet_id','JM','Diri','BM25']\n",
    "    bdj_df['JM']=round(bdj_df['JM'],2)                \n",
    "    bdj_df['Diri']=round(bdj_df['Diri'],2)                \n",
    "    bdj_df['BM25']=round(bdj_df['BM25'],2)\n",
    "    \n",
    "    #bdj_df.info()\n",
    "    \n",
    "    instr = p+ \"  \" + str(len(qn['tweet_id']))+\"  \"+str(len(bdj_df['tweet_id'])) +'\\n'\n",
    "    fout.write(instr)\n",
    "                          \n",
    "    #bdj_df.to_csv('C:/Users\\lenovo\\AnacondaProjects\\learning-to-rank-master\\experiments/test.txt',encoding='UTF-8',index=False,header=None,mode='a')\n",
    "    \n",
    "    qbdj_df=pd.merge(bdj_df,qn,how='inner',on=['tweet_id','profile'])\n",
    "    qbdj_df.columns=['profile','tweet_id','JM','Diri','BM25','Class']\n",
    "    qbdj_df['JM']=round(qbdj_df['JM'],2)                \n",
    "    qbdj_df['Diri']=round(qbdj_df['Diri'],2)                \n",
    "    qbdj_df['BM25']=round(qbdj_df['BM25'],2)\n",
    "    \n",
    "    qbdj_df['Class'] = qbdj_df.Class.apply(lambda x: x if not pd.isnull(x) else 0)\n",
    "    qbdj_df['Class']=qbdj_df.Class.astype(int)\n",
    "    #qbdj_df.info()\n",
    "    \n",
    "    qbdj_df.to_csv('C:/Users\\lenovo\\AnacondaProjects\\learning-to-rank-master\\experiments/gtest.txt',encoding='UTF-8',index=False,header=None,mode='a')\n",
    "\n",
    "    \n",
    "fout.close()  \n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RTS182'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jdf=pd.read_csv(p+'.txt',header=None,sep=',',names=['date', 'profile','q0','tweet_id','rank','score','text'])\n",
    "fout.close()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    34799\n",
      "1     3029\n",
      "Name: Class, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6058 entries, 22440 to 36329\n",
      "Data columns (total 6 columns):\n",
      "profile     6058 non-null object\n",
      "tweet_id    6058 non-null int64\n",
      "JM          6058 non-null float64\n",
      "Diri        6058 non-null float64\n",
      "BM25        6058 non-null float64\n",
      "Class       6058 non-null int64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 331.3+ KB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "X_train=pd.read_csv('C:/Users\\lenovo\\AnacondaProjects\\learning-to-rank-master\\experiments/sample.txt',sep=','\n",
    "                    ,header=None,names=['profile','tweet_id','JM','Diri','BM25','Class'])\n",
    "X_train.head()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train['JM'] = scaler.fit_transform(X_train[['JM']])\n",
    "X_train['Diri'] = scaler.fit_transform(X_train[['Diri']])\n",
    "X_train['BM25'] = scaler.fit_transform(X_train[['BM25']])       \n",
    "X_train.head()\n",
    "\n",
    "X_trainall['Class']=np.where(X_trainall['Class'] ==2,1, X_trainall['Class'])\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_trainall=pd.read_csv('C:/Users\\lenovo\\AnacondaProjects\\learning-to-rank-master\\experiments/sample.txt',sep=','\n",
    "                    ,header=None,names=['profile','tweet_id','JM','Diri','BM25','Class'])\n",
    "#X_trainall.head()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_trainall['JM'] = scaler.fit_transform(X_trainall[['JM']])\n",
    "X_trainall['Diri'] = scaler.fit_transform(X_trainall[['Diri']])\n",
    "X_trainall['BM25'] = scaler.fit_transform(X_trainall[['BM25']]) \n",
    "\n",
    "X_trainall['Class']=np.where(X_trainall['Class'] ==2,1, X_trainall['Class'])\n",
    "X_trainall.head()\n",
    "\n",
    "print(X_trainall['Class'].value_counts())\n",
    "X_train0=X_trainall[X_trainall['Class']==0]\n",
    "X_train1=X_trainall[X_trainall['Class']==1]\n",
    "#X_train0.info()\n",
    "#X_train1.info()\n",
    "X_train0=X_train0.sample(3029)\n",
    "#X_train0.info()\n",
    "X_trainws=pd.concat([X_train0,X_train1])\n",
    "X_train = X_trainws.reindex(np.random.permutation(X_trainws.index))\n",
    "X_train.info()\n",
    "#X_trainws.info()\n",
    "#X_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>JM</th>\n",
       "      <th>Diri</th>\n",
       "      <th>BM25</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RTS47</td>\n",
       "      <td>891302728198230020</td>\n",
       "      <td>3.050570</td>\n",
       "      <td>2.407051</td>\n",
       "      <td>3.571360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RTS47</td>\n",
       "      <td>891348035069935616</td>\n",
       "      <td>2.778155</td>\n",
       "      <td>1.815867</td>\n",
       "      <td>2.271354</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RTS47</td>\n",
       "      <td>891359347099320320</td>\n",
       "      <td>2.778155</td>\n",
       "      <td>1.815867</td>\n",
       "      <td>2.271354</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RTS47</td>\n",
       "      <td>891391584524279809</td>\n",
       "      <td>2.778155</td>\n",
       "      <td>1.815867</td>\n",
       "      <td>2.271354</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RTS47</td>\n",
       "      <td>891299170077769728</td>\n",
       "      <td>2.621369</td>\n",
       "      <td>1.806629</td>\n",
       "      <td>1.665027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  profile            tweet_id        JM      Diri      BM25  Class\n",
       "0   RTS47  891302728198230020  3.050570  2.407051  3.571360      1\n",
       "1   RTS47  891348035069935616  2.778155  1.815867  2.271354      2\n",
       "2   RTS47  891359347099320320  2.778155  1.815867  2.271354      2\n",
       "3   RTS47  891391584524279809  2.778155  1.815867  2.271354      2\n",
       "4   RTS47  891299170077769728  2.621369  1.806629  1.665027      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=pd.read_csv('C:/Users\\lenovo\\AnacondaProjects\\learning-to-rank-master\\experiments/gtest.txt',sep=','\n",
    "                    ,header=None,names=['profile','tweet_id','JM','Diri','BM25','Class'])\n",
    "X_test.head()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test['JM'] = scaler.fit_transform(X_test[['JM']])\n",
    "X_test['Diri'] = scaler.fit_transform(X_test[['Diri']])\n",
    "X_test['BM25'] = scaler.fit_transform(X_test[['BM25']])       \n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6058 entries, 17565 to 22657\n",
      "Data columns (total 6 columns):\n",
      "profile     6058 non-null object\n",
      "tweet_id    6058 non-null int64\n",
      "JM          6058 non-null float64\n",
      "Diri        6058 non-null float64\n",
      "BM25        6058 non-null float64\n",
      "Class       6058 non-null int64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 331.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train['Class']=np.where(X_train['Class'] ==2,1, X_train['Class'])\n",
    "X_test['Class']=np.where(X_test['Class'] ==-2,0, X_test['Class'])\n",
    "X_test['Class']=np.where(X_test['Class'] ==2,1, X_test['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    51755\n",
       "1     5561\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Class'].value_counts()\n",
    "X_test['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JM      Diri      BM25\n",
      "Class                              \n",
      "0     -0.091851 -0.099656 -0.088536\n",
      "1      0.942935  1.002133  0.886593\n"
     ]
    }
   ],
   "source": [
    "X_train1=X_train[['JM','Diri','BM25','Class']]\n",
    "print(X_train1.groupby('Class').mean())\n",
    "y_train=X_train['Class']\n",
    "xx_train=X_train1[['JM','Diri','BM25']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JM      Diri      BM25\n",
      "Class                              \n",
      "0     -0.087395 -0.094564 -0.076164\n",
      "1      0.813362  0.880082  0.708838\n"
     ]
    }
   ],
   "source": [
    "X_test1=X_test[['JM','Diri','BM25','Class']]\n",
    "print(X_test1.groupby('Class').mean())\n",
    "xx_test=X_test1[['JM','Diri','BM25']]\n",
    "y_test=X_test1['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57316, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(xx_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_test = logreg.predict(xx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75331495568427664"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39920, 11835],\n",
       "       [ 2304,  3257]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.215809700504\n",
      "0.585686027693\n",
      "0.315402120757\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         NR       0.95      0.77      0.85     51755\n",
      "          R       0.22      0.59      0.32      5561\n",
      "\n",
      "avg / total       0.87      0.75      0.80     57316\n",
      "\n",
      "0.678506234791\n"
     ]
    }
   ],
   "source": [
    "print (metrics.precision_score(y_test, y_pred_test))\n",
    "print(metrics.recall_score(y_test, y_pred_test))\n",
    "print (metrics.f1_score(y_test, y_pred_test))\n",
    "print(metrics.classification_report(y_test, y_pred_test,target_names=['NR','R']))\n",
    "#y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "#y_pred_prob\n",
    "print(metrics.roc_auc_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13018 entries, 0 to 13017\n",
      "Data columns (total 7 columns):\n",
      "date        13018 non-null int64\n",
      "profile     13018 non-null object\n",
      "q0          13018 non-null object\n",
      "tweet_id    13018 non-null int64\n",
      "rank        13018 non-null int64\n",
      "score       13018 non-null float64\n",
      "tag         13018 non-null object\n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 712.0+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test['Class_pred']=y_pred_test\n",
    "run_df=pd.read_csv('D:/datas/2017output/result/est-res2017/diri_linreg_est_20170.1 23.0_6.0.txt',sep=' '\n",
    "                    ,header=None,names=['date','profile','q0','tweet_id','rank','score','tag'])\n",
    "run_df.info()\n",
    "#X_test.to_csv('C:/Users\\lenovo\\AnacondaProjects\\learning-to-rank-master\\experiments/Test_res.txt',index=False,header=None,sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 959 entries, 0 to 958\n",
      "Data columns (total 1 columns):\n",
      "0    959 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 7.6 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11822 entries, 0 to 11821\n",
      "Data columns (total 1 columns):\n",
      "0    11822 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 92.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_test['Class_pred'].value_counts()\n",
    "\n",
    "rundft=run_df[['tweet_id']]\n",
    "rundft.head()\n",
    "X_testtid = X_test[X_test['Class_pred']==0]\n",
    "X_testtid=X_testtid[['tweet_id']]\n",
    "#X_testtid.info()\n",
    "\n",
    "ctid = pd.DataFrame(list(set(rundft['tweet_id'].tolist()) & set(X_testtid['tweet_id'].tolist())))\n",
    "ctid.info()\n",
    "ctid.columns=['tweet_id']\n",
    "#ltid=ctid[0].values.tolist()\n",
    "#len(ltid)\n",
    "#for tid in ltid:\n",
    " #   run_df.ix[~run_df['tweet_id']==tid]\n",
    "deltid=pd.DataFrame(list(set(rundft['tweet_id'].tolist()) - set(ctid['tweet_id'].tolist())))\n",
    "deltid.info()\n",
    "deltid.columns=['tweet_id']\n",
    "\n",
    "newrun_df=pd.merge(run_df,deltid,how='inner',on=['tweet_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13018 entries, 0 to 13017\n",
      "Data columns (total 7 columns):\n",
      "date        13018 non-null int64\n",
      "profile     13018 non-null object\n",
      "q0          13018 non-null object\n",
      "tweet_id    13018 non-null int64\n",
      "rank        13018 non-null int64\n",
      "score       13018 non-null float64\n",
      "tag         13018 non-null object\n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 712.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12026 entries, 0 to 12025\n",
      "Data columns (total 7 columns):\n",
      "date        12026 non-null int64\n",
      "profile     12026 non-null object\n",
      "q0          12026 non-null object\n",
      "tweet_id    12026 non-null int64\n",
      "rank        12026 non-null int64\n",
      "score       12026 non-null float64\n",
      "tag         12026 non-null object\n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 751.6+ KB\n"
     ]
    }
   ],
   "source": [
    "run_df.info()\n",
    "newrun_df.info()\n",
    "newrun_df.head()\n",
    "newrun_df.to_csv('D:/datas/2017output/result/lr-res/diripointlr.txt',sep=' ',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#per = Perceptron()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(6, 3, 1), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='logistic',solver='sgd',hidden_layer_sizes=(6,3,1))\n",
    "mlp.fit(xx_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_ntest = mlp.predict(xx_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 585]\n",
      " [  0 108]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred_ntest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.155844155844\n",
      "1.0\n",
      "0.269662921348\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         NR       0.00      0.00      0.00       585\n",
      "          R       0.16      1.00      0.27       108\n",
      "\n",
      "avg / total       0.02      0.16      0.04       693\n",
      "\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (metrics.precision_score(y_test, y_pred_ntest))\n",
    "print(metrics.recall_score(y_test, y_pred_ntest))\n",
    "print (metrics.f1_score(y_test, y_pred_ntest))\n",
    "print(metrics.classification_report(y_test, y_pred_ntest,target_names=['NR','R']))\n",
    "#y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "#y_pred_prob\n",
    "print(metrics.roc_auc_score(y_test, y_pred_ntest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    553\n",
       "1    140\n",
       "Name: Class_pred, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Class_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-final",
   "language": "python",
   "name": "lr-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
